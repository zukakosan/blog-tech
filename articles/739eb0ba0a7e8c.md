---
title: "Azure Monitor Agentを利用したカスタムテキストログの収集"
emoji: "🔎"
type: "tech"
topics:
  - "azure"
  - "log"
  - "monitor"
published: true
published_at: "2023-03-02 10:37"
publication_name: "microsoft"
---

現在Azure Monitorでカスタムログの収集というと、Log Analyticsエージェント(MMA/OMS)を使う方法とAzure Monitor Agent (AMA)を使う方法の2パターンが存在します。しかし、MMAについては2024年8月末にリタイアとなるため、AMA を利用するのが現在の推奨です。
AMAを利用するカスタムログの収集については、MSLearn[^1] に方法がまとまっていましたが、わかりづらい点があるためメモとして記載しておきます。

[^1]: https://learn.microsoft.com/ja-jp/azure/azure-monitor/agents/data-collection-text-log?tabs=portal

# カスタムテーブルの作成
MSLearn ではPowerShellで作成する方法が紹介されています。しかしながら、Azure portal から作成するとデータ収集ルール (DCR) およびデータ収集エンドポイント (DCE) も同時に作成されてしまうため、PowerShell のコマンドでテーブルの作成を行う方が意図した挙動になると思います。
PowerShell では次のコマンドを実行します。必要に応じて適宜名称変更等を行ってください。

```powershell
$tableParams = @'
{
   "properties": {
       "schema": {
              "name": "{TableName}_CL",
              "columns": [
       {
                               "name": "TimeGenerated",
                               "type": "DateTime"
                       }, 
                      {
                               "name": "RawData",
                               "type": "String"
                      }
             ]
       }
   }
}
'@

Invoke-AzRestMethod -Path "/subscriptions/{subscription}/resourcegroups/{resourcegroup}/providers/microsoft.operationalinsights/workspaces/{WorkspaceName}/tables/{TableName}_CL?api-version=2021-12-01-preview" -Method PUT -payload $tableParams
```
コマンド実行後きちんとテーブルが作成されていることを確認します。現時点ではまだ何も設定していないので、テーブルのスキーマだけが作成された状態です。

![](https://storage.googleapis.com/zenn-user-upload/6dd1dd0d3252-20230302.png)

:::message
- Azure portal 上で DCR 用のテーブルを作ろうとすると後の構成で失敗する可能性がある
- 一旦 Log Analytics エージェント用のカスタムログテーブルを作って、そこにデータ収集ルールでカスタムログを注入するのも手か？
	- ただ、MMA 用のテーブルを作成すると、MMA と AMA の両側からデータ収集される可能性があり、レコードが重複する可能性がある？
	- 試していない
	- ![](https://storage.googleapis.com/zenn-user-upload/21030f0483ef-20230302.png)
- (リタイアが予定されているので削除) ~~MMAベースの方はサンプルのログファイルからスキーマを読み取ってくれるので楽~~
	- ![](https://storage.googleapis.com/zenn-user-upload/5726d9c4754c-20230302.png)
	- ![](https://storage.googleapis.com/zenn-user-upload/8b20fbdf885e-20230302.png)

- DCR ベースの方もこういう形式にしてほしいのだが、、、
	- なぜか DCR ベースのテーブルを作成するタイミングで DCR と DCE を選択させられる
		- ![](https://storage.googleapis.com/zenn-user-upload/fdc9d06b8829-20230302.png)
	- 加えて、ログスキーマは JSON である必要がある

- よって PowerShell で作成する方が無難かもしれない
:::

# DCR の作成
Azure portal で DCR を作成します。カスタムログの収集には DCE が必要となります。事前に作成しておきましょう。リソースとして VM を追加すると、VM のマネージド ID が有効になります。
> ポータルは、既存のユーザー割り当て ID と共に、ターゲット リソースでシステム割り当てマネージド ID を有効にします (該当する場合)。 既存のアプリケーションでは、ユーザー割り当て ID を要求で指定しない限り、マシンでは既定でシステム割り当て ID が代わりに使用されます。

## データソース
ファイル名にはワイルドカードが使えるが、ディレクトリ名にはワイルドカードが使えません。つまり、対象ファイルを `C:\DirA\DirB\*log.txt` のような形で表現可能ということです。

例えば、Docker コンテナーのログを監視したい場合には、`/var/lib/docker/containers/${container_id}/${container_id}-json.log` を監視したくなりますが、ディレクトリ名にワイルドカードが使えないため、`${container_id}` の部分をどのように全取得するのかは実装を考える必要があります。Docker のログをテキストではなくホスト マシン上の Syslog に指定するのも一案かと思います。本筋ではないので深入りはしません。

テーブル名には既存のテーブルしか受け入れられないため、先にカスタムテーブルを作成する必要があります。
![](https://storage.googleapis.com/zenn-user-upload/5ad71e293892-20230302.png)

# ログファイルの配置
対象 VM の設定したファイル パスにサンプル ファイルを配置します。
![](https://storage.googleapis.com/zenn-user-upload/9a611aee39c7-20230302.png)

# Log Analytics ワークスペースでの確認
ログ ファイルの配置から Log Analytics 側へのデータ収集は最大~~5分かかる~~ 2 時間ほどかかる場合があるようです[^2]。検証には時間と心の余裕が必要です。
[^2]: https://t.co/s7CepUUZRK

カスタムテーブルにクエリを書いて存在を確認します。
![](https://storage.googleapis.com/zenn-user-upload/0df9476448d1-20230302.png)

# おわり
こういうエージェントによるデータ収集待ちの構成はタイムラグがつきもので、構成自体に失敗しているのかすぐにわからない点が難しいポイントです。時間と心に余裕のあるうちに検証をしましょう。




	